{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8804877,"sourceType":"datasetVersion","datasetId":5295388},{"sourceId":8807393,"sourceType":"datasetVersion","datasetId":5297057}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir data\n!mkdir saved_models\n!mkdir data/trainA data/trainB data/trainA_resized data/trainB_resized","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:31:48.847156Z","iopub.execute_input":"2024-06-28T04:31:48.847461Z","iopub.status.idle":"2024-06-28T04:31:51.711053Z","shell.execute_reply.started":"2024-06-28T04:31:48.847434Z","shell.execute_reply":"2024-06-28T04:31:51.709608Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os, shutil\nimages = os.listdir(\"/kaggle/input/utkface/UTKFace\")\nfor f in images:\n  try:\n    val = f.split(\"_\")\n    age = int(val[0])\n    race = int(val[2])\n    if(age >=20 and age<=30):\n      shutil.copy(\"/kaggle/input/utkface/UTKFace/\"+f, \"/kaggle/working/data/trainA\")\n    if(age >=50 and age<=60):\n      shutil.copy(\"/kaggle/input/utkface/UTKFace/\"+f, \"/kaggle/working/data/trainB\")   \n  except:\n    print(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:31:58.664141Z","iopub.execute_input":"2024-06-28T04:31:58.664977Z","iopub.status.idle":"2024-06-28T04:33:08.183871Z","shell.execute_reply.started":"2024-06-28T04:31:58.664942Z","shell.execute_reply":"2024-06-28T04:33:08.182876Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"61_1_20170109142408075.jpg.chip.jpg\n61_1_20170109150557335.jpg.chip.jpg\n39_1_20170116174525125.jpg.chip.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\n\n# Source path (assuming the file is in /kaggle/input)\nsource_path = '/kaggle/input/savedfile/checkpoint_final.pth'\n\n# Destination path\ndestination_path = '/kaggle/working/saved_models/checkpoint_fianl.pth'\n\n# Move the file\nshutil.copyfile(source_path, destination_path)\n\n# Verify the file is in the destination path\nimport os\nos.listdir('/kaggle/working/saved_models')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:34:01.857366Z","iopub.execute_input":"2024-06-28T04:34:01.858147Z","iopub.status.idle":"2024-06-28T04:34:02.380907Z","shell.execute_reply.started":"2024-06-28T04:34:01.858119Z","shell.execute_reply":"2024-06-28T04:34:02.379756Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['checkpoint_fianl.pth']"},"metadata":{}}]},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\ndef downscale_images(input_dir, output_dir, new_size):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for filename in os.listdir(input_dir):\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n            img_path = os.path.join(input_dir, filename)\n            img = Image.open(img_path)\n            \n            # Downscale the image\n            img = img.resize(new_size, Image.ANTIALIAS)\n            \n            # Save the downscaled image\n            img.save(os.path.join(output_dir, filename))\n\ninput_directory = '/kaggle/working/data/trainB'\noutput_directory = '/kaggle/working/data/trainB_resized'\nnew_size = (100, 100)  # Specify the new size as (width, height)\n\ndownscale_images(input_directory, output_directory, new_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:34:38.825241Z","iopub.execute_input":"2024-06-28T04:34:38.825600Z","iopub.status.idle":"2024-06-28T04:34:42.562524Z","shell.execute_reply.started":"2024-06-28T04:34:38.825572Z","shell.execute_reply":"2024-06-28T04:34:42.561641Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1997202276.py:13: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n  img = img.resize(new_size, Image.ANTIALIAS)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom PIL import Image\nimport numpy as np\nimport os\nimport glob\nimport datetime\nimport itertools\n\nclass ImageDataset(Dataset):\n    def __init__(self, root, transforms_=None, mode='train'):\n        self.transform = transforms_\n        self.files_A = sorted(glob.glob(os.path.join(root, '%sA_resized' % mode) + '/*.*'))\n        self.files_B = sorted(glob.glob(os.path.join(root, '%sB_resized' % mode) + '/*.*'))\n\n    def __getitem__(self, index):\n        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]))\n        item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]))\n\n        return {'A': item_A, 'B': item_B}\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))\n\nclass ReplayBuffer():\n    def __init__(self, max_size=50):\n        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n        self.max_size = max_size\n        self.data = []\n\n    def push_and_pop(self, data):\n        to_return = []\n        for element in data.data:\n            element = torch.unsqueeze(element, 0)\n            if len(self.data) < self.max_size:\n                self.data.append(element)\n                to_return.append(element)\n            else:\n                if np.random.uniform(0, 1) > 0.5:\n                    i = np.random.randint(0, self.max_size)\n                    to_return.append(self.data[i].clone())\n                    self.data[i] = element\n                else:\n                    to_return.append(element)\n        return torch.cat(to_return)\n\nclass GeneratorResNet(nn.Module):\n    def __init__(self, input_shape, num_residual_blocks):\n        super(GeneratorResNet, self).__init__()\n\n        self.input_shape = input_shape\n        self.num_residual_blocks = num_residual_blocks\n\n        # Initial convolution block\n        model = [nn.Conv2d(input_shape[0], 64, kernel_size=7, stride=1, padding=3, bias=False),\n                 nn.InstanceNorm2d(64),\n                 nn.ReLU(inplace=True)]\n\n        # Downsampling\n        in_features = 64\n        out_features = in_features*2\n        for _ in range(2):\n            model += [nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1, bias=False),\n                      nn.InstanceNorm2d(out_features),\n                      nn.ReLU(inplace=True)]\n            in_features = out_features\n            out_features = in_features*2\n\n        # Residual blocks\n        for _ in range(num_residual_blocks):\n            model += [ResidualBlock(in_features)]\n\n        # Upsampling\n        out_features = in_features//2\n        for _ in range(2):\n            model += [nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n                      nn.InstanceNorm2d(out_features),\n                      nn.ReLU(inplace=True)]\n            in_features = out_features\n            out_features = in_features//2\n\n        # Output layer\n        model += [nn.Conv2d(64, input_shape[0], kernel_size=7, stride=1, padding=3),\n                  nn.Tanh()]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n\n        conv_block = [nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1, bias=False),\n                      nn.InstanceNorm2d(in_features),\n                      nn.ReLU(inplace=True),\n                      nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1, bias=False),\n                      nn.InstanceNorm2d(in_features)]\n\n        self.conv_block = nn.Sequential(*conv_block)\n\n    def forward(self, x):\n        return x + self.conv_block(x)\n\nclass Discriminator(nn.Module):\n    def __init__(self, input_shape):\n        super(Discriminator, self).__init__()\n\n        self.input_shape = input_shape\n        in_channels, height, width = self.input_shape\n\n        def discriminator_block(in_filters, out_filters, normalize=True):\n            layers = [nn.Conv2d(in_filters, out_filters, kernel_size=4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *discriminator_block(in_channels, 64, normalize=False),\n            *discriminator_block(64, 128),\n            *discriminator_block(128, 256),\n            *discriminator_block(256, 512),\n            nn.ZeroPad2d((1, 0, 1, 0)),\n            nn.Conv2d(512, 1, kernel_size=4, padding=1)\n        )\n\n    def forward(self, img):\n        return self.model(img)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-28T04:34:53.528686Z","iopub.execute_input":"2024-06-28T04:34:53.529265Z","iopub.status.idle":"2024-06-28T04:34:58.495439Z","shell.execute_reply.started":"2024-06-28T04:34:53.529235Z","shell.execute_reply":"2024-06-28T04:34:58.494459Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CycleGAN():\n    def __init__(self, dataset_name='data', img_height=100, img_width=100, channels=3, lr=0.0002, b1=0.5, b2=0.999):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        self.img_height = img_height\n        self.img_width = img_width\n        self.channels = channels\n        self.input_shape = (self.channels, self.img_height, self.img_width)\n\n        self.dataset_name = dataset_name\n\n        # Initialize the generator and discriminator\n        self.G_AB = GeneratorResNet(self.input_shape, num_residual_blocks=9).to(self.device)\n        self.G_BA = GeneratorResNet(self.input_shape, num_residual_blocks=9).to(self.device)\n        self.D_A = Discriminator(self.input_shape).to(self.device)\n        self.D_B = Discriminator(self.input_shape).to(self.device)\n\n        # Initialize weights\n        self.G_AB.apply(self.weights_init_normal)\n        self.G_BA.apply(self.weights_init_normal)\n        self.D_A.apply(self.weights_init_normal)\n        self.D_B.apply(self.weights_init_normal)\n\n        # Losses\n        self.criterion_GAN = torch.nn.MSELoss().to(self.device)\n        self.criterion_cycle = torch.nn.L1Loss().to(self.device)\n        self.criterion_identity = torch.nn.L1Loss().to(self.device)\n\n        # Optimizers\n        self.optimizer_G = torch.optim.Adam(\n            itertools.chain(self.G_AB.parameters(), self.G_BA.parameters()), lr=lr, betas=(b1, b2))\n        self.optimizer_D_A = torch.optim.Adam(self.D_A.parameters(), lr=lr, betas=(b1, b2))\n        self.optimizer_D_B = torch.optim.Adam(self.D_B.parameters(), lr=lr, betas=(b1, b2))\n\n        # Buffers of previously generated samples\n        self.fake_A_buffer = ReplayBuffer()\n        self.fake_B_buffer = ReplayBuffer()\n\n        # Image transformations\n        self.transforms_ = transforms.Compose([\n            transforms.Resize(int(self.img_height * 1.12), Image.BICUBIC),\n            transforms.RandomCrop((self.img_height, self.img_width)),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,))\n        ])\n\n    def weights_init_normal(self, m):\n        classname = m.__class__.__name__\n        if classname.find('Conv') != -1:\n            torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n        elif classname.find('BatchNorm2d') != -1:\n            torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n            torch.nn.init.constant_(m.bias.data, 0.0)\n\n    def save_checkpoint(self, epoch, saving_dir):\n        os.makedirs(saving_dir, exist_ok=True)\n        checkpoint_path = os.path.join(saving_dir, f'checkpoint_{epoch}.pth')\n        torch.save({\n            'epoch': epoch,\n            'G_AB_state_dict': self.G_AB.state_dict(),\n            'G_BA_state_dict': self.G_BA.state_dict(),\n            'D_A_state_dict': self.D_A.state_dict(),\n            'D_B_state_dict': self.D_B.state_dict(),\n            'optimizer_G_state_dict': self.optimizer_G.state_dict(),\n            'optimizer_D_A_state_dict': self.optimizer_D_A.state_dict(),\n            'optimizer_D_B_state_dict': self.optimizer_D_B.state_dict(),\n        }, checkpoint_path)\n        print(f\"Checkpoint saved at {checkpoint_path}\")\n\n    def load_checkpoint(self, checkpoint_path):\n        checkpoint = torch.load(checkpoint_path)\n        self.G_AB.load_state_dict(checkpoint['G_AB_state_dict'])\n        self.G_BA.load_state_dict(checkpoint['G_BA_state_dict'])\n        self.D_A.load_state_dict(checkpoint['D_A_state_dict'])\n        self.D_B.load_state_dict(checkpoint['D_B_state_dict'])\n        self.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n        self.optimizer_D_A.load_state_dict(checkpoint['optimizer_D_A_state_dict'])\n        self.optimizer_D_B.load_state_dict(checkpoint['optimizer_D_B_state_dict'])\n        print(f\"Checkpoint loaded from {checkpoint_path}\")\n        return checkpoint['epoch']\n\n    def verify_checkpoint(self, checkpoint_path):\n        try:\n            checkpoint = torch.load(checkpoint_path)\n            required_keys = ['epoch', 'G_AB_state_dict', 'G_BA_state_dict', 'D_A_state_dict', 'D_B_state_dict',\n                             'optimizer_G_state_dict', 'optimizer_D_A_state_dict', 'optimizer_D_B_state_dict']\n            for key in required_keys:\n                if key not in checkpoint:\n                    print(f\"Checkpoint verification failed: Missing key '{key}'\")\n                    return False\n            print(f\"Checkpoint verification successful: {checkpoint_path}\")\n            return True\n        except Exception as e:\n            print(f\"Checkpoint verification failed: {e}\")\n            return False\n\n    def train(self, epochs, batch_size=1, sample_interval=50, saving_dir='/kaggle/working/saved_models', start_epoch=0):\n        # Load dataset\n        dataloader = DataLoader(ImageDataset(f'./{self.dataset_name}', transforms_=self.transforms_),\n                                batch_size=batch_size, shuffle=True, num_workers=0)\n\n        # Adversarial ground truths\n        valid = torch.ones((batch_size, 1, 6, 6), requires_grad=False).to(self.device)\n        fake = torch.zeros((batch_size, 1, 6, 6), requires_grad=False).to(self.device)\n\n        start_time = datetime.datetime.now()\n\n        for epoch in range(start_epoch, epochs):\n            for i, batch in enumerate(dataloader):\n\n                # Set model input\n                real_A = batch['A'].to(self.device)\n                real_B = batch['B'].to(self.device)\n\n                # ----------------------\n                #  Train Generators\n                # ----------------------\n\n                self.optimizer_G.zero_grad()\n\n                # Identity loss\n                loss_id_A = self.criterion_identity(self.G_BA(real_A), real_A)\n                loss_id_B = self.criterion_identity(self.G_AB(real_B), real_B)\n\n                loss_identity = (loss_id_A + loss_id_B) / 2\n\n                # GAN loss\n                fake_B = self.G_AB(real_A)\n                loss_GAN_AB = self.criterion_GAN(self.D_B(fake_B), valid)\n                fake_A = self.G_BA(real_B)\n                loss_GAN_BA = self.criterion_GAN(self.D_A(fake_A), valid)\n\n                loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n\n                # Cycle loss\n                recov_A = self.G_BA(fake_B)\n                loss_cycle_A = self.criterion_cycle(recov_A, real_A)\n                recov_B = self.G_AB(fake_A)\n                loss_cycle_B = self.criterion_cycle(recov_B, real_B)\n\n                loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n\n                # Total loss\n                loss_G = loss_GAN + 10.0 * loss_cycle + 5.0 * loss_identity\n\n                loss_G.backward()\n                self.optimizer_G.step()\n\n                # -----------------------\n                #  Train Discriminator A\n                # -----------------------\n\n                self.optimizer_D_A.zero_grad()\n\n                # Real loss\n                loss_real = self.criterion_GAN(self.D_A(real_A), valid)\n                # Fake loss (on batch of previously generated samples)\n                fake_A_ = self.fake_A_buffer.push_and_pop(fake_A)\n                loss_fake = self.criterion_GAN(self.D_A(fake_A_.detach()), fake)\n\n                # Total loss\n                loss_D_A = (loss_real + loss_fake) / 2\n\n                loss_D_A.backward()\n                self.optimizer_D_A.step()\n\n                # -----------------------\n                #  Train Discriminator B\n                # -----------------------\n\n                self.optimizer_D_B.zero_grad()\n\n                # Real loss\n                loss_real = self.criterion_GAN(self.D_B(real_B), valid)\n                # Fake loss (on batch of previously generated samples)\n                fake_B_ = self.fake_B_buffer.push_and_pop(fake_B)\n                loss_fake = self.criterion_GAN(self.D_B(fake_B_.detach()), fake)\n\n                # Total loss\n                loss_D_B = (loss_real + loss_fake) / 2\n\n                loss_D_B.backward()\n                self.optimizer_D_B.step()\n\n                loss_D = (loss_D_A + loss_D_B) / 2\n\n                # --------------\n                #  Log Progress\n                # --------------\n\n                batches_done = epoch * len(dataloader) + i\n                batches_left = epochs * len(dataloader) - batches_done\n                time_left = datetime.timedelta(seconds=batches_left * (datetime.datetime.now() - start_time).seconds / max(1, batches_done))\n\n                print(f'\\r[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {loss_D.item()}] [G loss: {loss_G.item()}] '\n                      f'[Adv: {loss_GAN.item()}] [Cycle: {loss_cycle.item()}] [Identity: {loss_identity.item()}] ETA: {time_left}', end='')\n\n                # If at sample interval save image\n                if batches_done % sample_interval == 0:\n                    self.sample_images(batches_done, epoch)\n\n            # Save model checkpoints\n            if epoch % 8 == 0:\n                self.save_checkpoint(epoch, saving_dir)\n                # Verify the checkpoint\n                checkpoint_path = os.path.join(saving_dir, f'checkpoint_{epoch}.pth')\n                if not self.verify_checkpoint(checkpoint_path):\n                    print(\"Warning: Checkpoint verification failed.\")\n\n    def sample_images(self, batches_done, epoch):\n        os.makedirs('/kaggle/working/images/%s/%s' % (self.dataset_name,epoch), exist_ok=True)\n        imgs = next(iter(DataLoader(ImageDataset(f'./{self.dataset_name}', transforms_=self.transforms_, mode='train'), batch_size=5, shuffle=True)))\n        real_A = imgs['A'].to(self.device)\n        real_B = imgs['B'].to(self.device)\n        fake_B = self.G_AB(real_A)\n        fake_A = self.G_BA(real_B)\n        recov_A = self.G_BA(fake_B)\n        recov_B = self.G_AB(fake_A)\n        img_sample = torch.cat((real_A.data, fake_B.data, recov_A.data, real_B.data, fake_A.data, recov_B.data), 0)\n        save_image(img_sample, '/kaggle/working/images/%s/%s/%s.png' % (self.dataset_name,epoch, batches_done), nrow=5, normalize=True)\n\n# Assume other necessary classes and methods like GeneratorResNet, Discriminator, ReplayBuffer, and ImageDataset are already defined.\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:54:23.743538Z","iopub.execute_input":"2024-06-28T04:54:23.743885Z","iopub.status.idle":"2024-06-28T04:54:23.785814Z","shell.execute_reply.started":"2024-06-28T04:54:23.743861Z","shell.execute_reply":"2024-06-28T04:54:23.784856Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"cyclegan = CycleGAN()\n# cyclegan.train(epochs=100, batch_size=1, sample_interval=1000)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:54:27.688223Z","iopub.execute_input":"2024-06-28T04:54:27.688956Z","iopub.status.idle":"2024-06-28T04:54:27.970865Z","shell.execute_reply.started":"2024-06-28T04:54:27.688923Z","shell.execute_reply":"2024-06-28T04:54:27.969895Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Initialize the CycleGAN model\ncyclegan = CycleGAN()\n\n# Load the checkpoint if exists\ncheckpoint_path = '/kaggle/working/saved_models/checkpoint_fianl.pth'\nif os.path.exists(checkpoint_path):\n    if cyclegan.verify_checkpoint(checkpoint_path):\n        start_epoch = cyclegan.load_checkpoint(checkpoint_path)\n        print(f\"Checkpoint loaded. Resuming from epoch {start_epoch}\")\n    else:\n        print(\"Checkpoint verification failed. Starting from scratch.\")\n        start_epoch = 0\nelse:\n    print(\"No checkpoint found. Starting from scratch.\")\n    start_epoch = 0\n\n# Train the model\nepochs = 100\ncyclegan.train(epochs=epochs, batch_size=1, sample_interval=100, start_epoch=start_epoch)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T04:54:30.458812Z","iopub.execute_input":"2024-06-28T04:54:30.459548Z","iopub.status.idle":"2024-06-28T15:06:58.426938Z","shell.execute_reply.started":"2024-06-28T04:54:30.459518Z","shell.execute_reply":"2024-06-28T15:06:58.425210Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Checkpoint verification successful: /kaggle/working/saved_models/checkpoint_fianl.pth\nCheckpoint loaded from /kaggle/working/saved_models/checkpoint_fianl.pth\nCheckpoint loaded. Resuming from epoch 28\n[Epoch 32/100] [Batch 8067/8068] [D loss: 0.18125218152999878] [G loss: 0.6547077894210815] [Adv: 0.2612316310405731] [Cycle: 0.028009558096528053] [Identity: 0.022676104679703712] ETA: 2:16:52.62179765Checkpoint saved at /kaggle/working/saved_models/checkpoint_32.pth\nCheckpoint verification successful: /kaggle/working/saved_models/checkpoint_32.pth\n[Epoch 40/100] [Batch 8067/8068] [D loss: 0.1728082001209259] [G loss: 1.066646695137024] [Adv: 0.5533325672149658] [Cycle: 0.03667017072439194] [Identity: 0.029322471469640732] ETA: 4:12:07.10189909498Checkpoint saved at /kaggle/working/saved_models/checkpoint_40.pth\nCheckpoint verification successful: /kaggle/working/saved_models/checkpoint_40.pth\n[Epoch 48/100] [Batch 8067/8068] [D loss: 0.2708256244659424] [G loss: 0.690233051776886] [Adv: 0.32320117950439453] [Cycle: 0.027361728250980377] [Identity: 0.018682921305298805] ETA: 4:54:33.14888015Checkpoint saved at /kaggle/working/saved_models/checkpoint_48.pth\nCheckpoint verification successful: /kaggle/working/saved_models/checkpoint_48.pth\n[Epoch 56/100] [Batch 8067/8068] [D loss: 0.18510445952415466] [G loss: 0.8864923715591431] [Adv: 0.43055206537246704] [Cycle: 0.03440886735916138] [Identity: 0.02237032540142536] ETA: 4:54:40.633270123Checkpoint saved at /kaggle/working/saved_models/checkpoint_56.pth\nCheckpoint verification successful: /kaggle/working/saved_models/checkpoint_56.pth\n[Epoch 61/100] [Batch 6076/8068] [D loss: 0.17975673079490662] [G loss: 0.9824166893959045] [Adv: 0.49284833669662476] [Cycle: 0.036934882402420044] [Identity: 0.02404390648007393] ETA: 4:41:29.1080001","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"[Epoch 72/100] [Batch 8067/8068] [D loss: 0.14476937055587769] [G loss: 0.996878981590271] [Adv: 0.47405314445495605] [Cycle: 0.04027056694030762] [Identity: 0.024024033918976784] ETA: 3:44:02.755767704Checkpoint saved at /kaggle/working/saved_models/checkpoint_72.pth\nCheckpoint verification successful: /kaggle/working/saved_models/checkpoint_72.pth\n[Epoch 73/100] [Batch 4012/8068] [D loss: 0.3030019998550415] [G loss: 0.6541820764541626] [Adv: 0.2617085576057434] [Cycle: 0.028704984113574028] [Identity: 0.02108474262058735] ETA: 3:40:50.412671986","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mcyclegan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[25], line 124\u001b[0m, in \u001b[0;36mCycleGAN.train\u001b[0;34m(self, epochs, batch_size, sample_interval, saving_dir, start_epoch)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Identity loss\u001b[39;00m\n\u001b[1;32m    123\u001b[0m loss_id_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_identity(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG_BA(real_A), real_A)\n\u001b[0;32m--> 124\u001b[0m loss_id_B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_identity(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mG_AB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_B\u001b[49m\u001b[43m)\u001b[49m, real_B)\n\u001b[1;32m    126\u001b[0m loss_identity \u001b[38;5;241m=\u001b[39m (loss_id_A \u001b[38;5;241m+\u001b[39m loss_id_B) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# GAN loss\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[7], line 94\u001b[0m, in \u001b[0;36mGeneratorResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[7], line 109\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/instancenorm.py:87\u001b[0m, in \u001b[0;36m_InstanceNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_no_batch_dim():\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_no_batch_input(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_instance_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/instancenorm.py:36\u001b[0m, in \u001b[0;36m_InstanceNorm._apply_instance_norm\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_instance_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2523\u001b[0m, in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_input_stats:\n\u001b[1;32m   2522\u001b[0m     _verify_spatial_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_input_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}